#Author				:	Papaioannou Vassilis
#Last update		:	28/ 03/ 2016
#Previous update	:	01/ 03/ 2016, 09/ 02/ 2016
#Platform			:	ASAP IReS
#Github				:	https://github.com/project-asap/IReS-Platform
#Work package		:	Telecom analytics
#Github				:	https://github.com/project-asap/telecom-analytics/blob/current/docs/PeakDetection.md
################################################################################
#
#Description
#	This is the concrete version of the distribution_computation operator from
#	wind workflow.
#Description_End

#################
# CONFIGURATION #
#################
#OPERATOR
Constraints.OpSpecification.Algorithm.name=Wind_Distribution_Computation
#ENGINE
Constraints.Engine=Spark
Constraints.EngineSpecification.Distributed=Spark
#INPUT( mandatory)
Constraints.Input.number=1
Constraints.Input0.Engine.FS=HDFS
#Constraints.Input0.type=TextFile
#OUTPUT( mandatory)
Constraints.Output.number=1
Constraints.Output0.Engine.FS=HDFS

############
# MODELING #
############
#OPTIMIZATION METRIC( mandatory inputSpace, outputSpace properties)
Optimization.inputSpace.In0.size=Double,1E8,1E10,l
Optimization.model.execTime=gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.execTime=3.0
Optimization.outputSpace.execTime=Double
Optimization.model.cost=gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.cost=1.0

#############
# EXECUTION #
#############
#LUA CONFIGURATION FILE( mandatory)
Execution.LuaScript=Distribution_Computation_Spark.lua
#EXECUTION ARGUMENTS( optional)
Execution.Arguments.number=4
Execution.Argument0=spark://131.114.136.218:7077
Execution.Argument1=typical_distribution_computation.py
Execution.Argument2=roma
Execution.Argument3=june-2015
#EXECUTION OUTPUT( mandatory)
Execution.Output0.path=$AS_IShdfs:///peaks/weekly_presence-roma-june-2015
